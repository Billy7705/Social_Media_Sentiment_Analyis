{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c829d3dd",
   "metadata": {},
   "source": [
    "-----\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h1> Twitter Scraper </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849bd93",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">  \n",
    "    \n",
    "<h3><b>In this Notebook we scrape tweets from Twitter using the snscrape library and upload the data to a csv file. \n",
    "</b></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0585d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80270e3d",
   "metadata": {},
   "source": [
    "We start by setting the variables we will be using in our scraper query. In this example, we will be scraping tweets including the words Joe Rogan. We scrape up to 10,000 tweets per day, for 500 days, starting on October 1st 2020. For each tweet, we will scrape the date it was posted, the text of the tweet, and the like count of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786f8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = 'Joe Rogan' # the key words we will filter for when scraping tweets\n",
    "max_tweets_per_day = 10000 # the max number of tweets scraped each day\n",
    "total_number_of_days = 500 # total number of days we will scrape for\n",
    "start_date = datetime.datetime(2020, 10, 1) # the first date we will start scraping tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7688f8f",
   "metadata": {},
   "source": [
    "Having set our key variables, we go on to scrape the twitter data using the snsscraper api and write the data directly to a csv file we will later upload to an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6c4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we write to a csvfile in the following path\n",
    "with open('data/twitter_data', 'w') as f:\n",
    "      \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow(fields)\n",
    "\n",
    "    # we set a start date we will increment on in the following loop\n",
    "    date = start_date\n",
    "    \n",
    "    # Using TwitterSearchScraper to scrape data \n",
    "    for i in range(total_number_of_days):\n",
    "        \n",
    "        # we update the date information we will pass into the scraper query\n",
    "        date_string = date.strftime(\"%Y-%m-%d\")\n",
    "        date += datetime.timedelta(days=1)\n",
    "        next_date_string = date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # we update the scraper query to search for tweets containing our key words on a given date\n",
    "        q = f\"{key_words} since:{date_string} until:{next_date_string}\"\n",
    "        \n",
    "        # we get up to 10,000 tweets according to our query and write them into the csv file\n",
    "        try:\n",
    "            for j,tweet in enumerate(sntwitter.TwitterSearchScraper(q).get_items()):\n",
    "                if j>max_tweets_per_day:\n",
    "                    break\n",
    "                tweet_data = [tweet.date, tweet.content, tweet.likeCount]\n",
    "                write.writerow(tweet_data)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9bd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['date', 'text', 'like_count']\n",
    "with open('joe_rogan_tweets', 'w') as f:\n",
    "      \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow(fields)\n",
    "    write.writerows(tweets_list2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
